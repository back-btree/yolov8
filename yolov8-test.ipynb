{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec222b2a-e8d7-47fc-ad4e-ec88ba6e3fee",
   "metadata": {},
   "source": [
    "YOLOv8 ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043ba367-06e4-4b20-aedd-28328b434f1b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.103-py3-none-any.whl (585 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 585 kB 12.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (4.64.1)\n",
      "Collecting sentry-sdk\n",
      "  Downloading sentry_sdk-1.23.0-py2.py3-none-any.whl (205 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 205 kB 108.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (3.4.3)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (8.4.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (2.28.1)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293 kB 110.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (4.7.0.68)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.3.4)\n",
      "Collecting thop>=0.1.1\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.4.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from ultralytics) (5.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (0.14.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->ultralytics) (2022.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (8.5.0.96)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->ultralytics) (65.5.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->ultralytics) (0.36.2)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140 kB 108.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib>=3.2.2->ultralytics) (1.15.0)\n",
      "Installing collected packages: urllib3, thop, sentry-sdk, seaborn, ultralytics\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterhubutils 0.25.0 requires jinja2<3.0.0,>=2.0.0, but you have jinja2 3.1.2 which is incompatible.\n",
      "jupyterhubutils 0.25.0 requires jupyter-client<7.0.0,>=5.0.0, but you have jupyter-client 8.2.0 which is incompatible.\u001b[0m\n",
      "Successfully installed seaborn-0.12.2 sentry-sdk-1.23.0 thop-0.1.1.post2209072238 ultralytics-8.0.103 urllib3-1.26.15\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd7b42-c0aa-445a-81a4-7ce8026b9298",
   "metadata": {},
   "source": [
    "íŒ¨í‚¤ì§€ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99bfaa1e-3c7a-41b1-befd-eb002a70ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8db30-3b0a-425f-adb9-7bb84cd52fe8",
   "metadata": {},
   "source": [
    "ì´ë¯¸ì§€ ì €ì¥\n",
    "ultralytics githubì— ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì.\n",
    "urllib íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆë‹¤.\n",
    "urllib.request.urlretrieve(\"url ê²½ë¡œ\", 'ì €ì¥í•  ì´ë¦„')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0902a8f-3d68-457a-9238-1eb31bf2f6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/bus.jpg', <http.client.HTTPMessage at 0x7f290ed85b50>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download image\n",
    "os.makedirs('data', exist_ok=True)\n",
    "urllib.request.urlretrieve(\"https://ultralytics.com/images/bus.jpg\", 'data/bus.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e7dae5-2422-4aec-ad83-cf16faafaea1",
   "metadata": {},
   "source": [
    "yolov8ë¡œ ë°”ë€Œë©´ì„œ ê¸°ì¡´ yolov5ì™€ ê°€ì¥ í° ë³€í™”ê°€ íŒ¨í‚¤ì§€í™”ê°€ ëœ ê²ƒì´ë‹¤.\n",
    "ë¬¼ë¡  ultralytics ê¹ƒí˜ì´ì§€ì—ì„œ git cloneì„ í†µí•´ ê¸°ì¡´ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ\n",
    "ë³€í™”ì˜ íŠ¸ë Œë“œì— ë§ì¶° git cloneí•˜ì§€ ì•Šê³  ìœ ì§€ë³´ìˆ˜í•˜ê¸° ì¢‹ê²Œ pip íŒ¨í‚¤ì§€ë¡œë§Œ ì§„í–‰í•  ì˜ˆì •ì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6e5d3d-a944-4e21-bd77-0142372532aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to pretrained/yolov8s.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576c085f3a454bb99d9e0d971ad17a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/21.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "model = YOLO(\"./pretrained/yolov8s.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4161c9-62fc-4f16-ae01-524dfb9fabf4",
   "metadata": {},
   "source": [
    "yaml íŒŒì¼ ì¤€ë¹„\n",
    "customizing í•˜ëŠ”ë° í•„ìš”í•œ ì¤€ë¹„ë¬¼ë¡œ dataset yaml íŒŒì¼ê³¼ cfg yaml íŒŒì¼ì´ í•„ìš”í•˜ë‹¤.\n",
    "í•´ë‹¹ íŒŒì¼ë“¤ì€ ultralytics githubì—ë„ ìˆì§€ë§Œ íŒ¨í‚¤ì§€ ì•ˆì— ì¡´ì¬í•˜ë¯€ë¡œ ë‚˜ëŠ” ì£¼ë¡œ íŒ¨í‚¤ì§€ ë‚´ì—ì„œ ê²€ìƒ‰í•´ì„œ ì°¾ê³  ë³µì‚¬í•´ì„œ ë‚´ í´ë” ë‚´ ë”°ë¡œ ë§Œë“¤ì–´ ì¤€ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6274b-3dc2-4e0c-bd8c-65291e4a3d26",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì…‹ ì„¤ì • : coco128.yaml"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6f13079-4a9f-4d90-b78f-95a69b2096a0",
   "metadata": {},
   "source": [
    "# Ultralytics YOLO ğŸš€, GPL-3.0 license\n",
    "# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics\n",
    "# Example usage: yolo train data=coco128.yaml\n",
    "# parent\n",
    "# â”œâ”€â”€ yolov5\n",
    "# â””â”€â”€ datasets\n",
    "#     â””â”€â”€ coco128  â† downloads here (7 MB)\n",
    "\n",
    "\n",
    "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "path: ../datasets/coco128  # dataset root dir\n",
    "train: images/train2017  # train images (relative to 'path') 128 images\n",
    "val: images/train2017  # val images (relative to 'path') 128 images\n",
    "test:  # test images (optional)\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: person\n",
    "  1: bicycle\n",
    "  2: car\n",
    "  3: motorcycle\n",
    "  4: airplane\n",
    "  5: bus\n",
    "  6: train\n",
    "  7: truck\n",
    "  8: boat\n",
    "  9: traffic light\n",
    "  10: fire hydrant\n",
    "  11: stop sign\n",
    "  12: parking meter\n",
    "  13: bench\n",
    "  14: bird\n",
    "  15: cat\n",
    "  16: dog\n",
    "  17: horse\n",
    "  18: sheep\n",
    "  19: cow\n",
    "  20: elephant\n",
    "  21: bear\n",
    "  22: zebra\n",
    "  23: giraffe\n",
    "  24: backpack\n",
    "  25: umbrella\n",
    "  26: handbag\n",
    "  27: tie\n",
    "  28: suitcase\n",
    "  29: frisbee\n",
    "  30: skis\n",
    "  31: snowboard\n",
    "  32: sports ball\n",
    "  33: kite\n",
    "  34: baseball bat\n",
    "  35: baseball glove\n",
    "  36: skateboard\n",
    "  37: surfboard\n",
    "  38: tennis racket\n",
    "  39: bottle\n",
    "  40: wine glass\n",
    "  41: cup\n",
    "  42: fork\n",
    "  43: knife\n",
    "  44: spoon\n",
    "  45: bowl\n",
    "  46: banana\n",
    "  47: apple\n",
    "  48: sandwich\n",
    "  49: orange\n",
    "  50: broccoli\n",
    "  51: carrot\n",
    "  52: hot dog\n",
    "  53: pizza\n",
    "  54: donut\n",
    "  55: cake\n",
    "  56: chair\n",
    "  57: couch\n",
    "  58: potted plant\n",
    "  59: bed\n",
    "  60: dining table\n",
    "  61: toilet\n",
    "  62: tv\n",
    "  63: laptop\n",
    "  64: mouse\n",
    "  65: remote\n",
    "  66: keyboard\n",
    "  67: cell phone\n",
    "  68: microwave\n",
    "  69: oven\n",
    "  70: toaster\n",
    "  71: sink\n",
    "  72: refrigerator\n",
    "  73: book\n",
    "  74: clock\n",
    "  75: vase\n",
    "  76: scissors\n",
    "  77: teddy bear\n",
    "  78: hair drier\n",
    "  79: toothbrush\n",
    "\n",
    "\n",
    "# Download script/URL (optional)\n",
    "download: https://ultralytics.com/assets/coco128.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c7d86-9f95-4553-afb7-a4b3b8a972dc",
   "metadata": {},
   "source": [
    "config : default.yaml ì„ custom.yaml ë¡œ ë³€ê²½í•˜ì—¬ í™œìš©í•œë‹¤."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7852b52-cc32-45ce-b3e5-be5ee57b672c",
   "metadata": {},
   "source": [
    "# Ultralytics YOLO ğŸš€, GPL-3.0 license\n",
    "# Default training settings and hyperparameters for medium-augmentation COCO training\n",
    "\n",
    "task: detect  # inference task, i.e. detect, segment, classify\n",
    "mode: train  # YOLO mode, i.e. train, val, predict, export\n",
    "\n",
    "# Train settings -------------------------------------------------------------------------------------------------------\n",
    "model: ./pretrained/yolov8s.pt # path to model file, i.e. yolov8n.pt, yolov8n.yaml\n",
    "data: ./dataset/coco128.yaml # path to data file, i.e. coco128.yaml\n",
    "epochs: 1  # number of epochs to train for\n",
    "patience: 50  # epochs to wait for no observable improvement for early stopping of training\n",
    "batch: 16  # number of images per batch (-1 for AutoBatch)\n",
    "imgsz: 640  # size of input images as integer or w,h\n",
    "save: True  # save train checkpoints and predict results\n",
    "save_period: -1 # Save checkpoint every x epochs (disabled if < 1)\n",
    "cache: False  # True/ram, disk or False. Use cache for data loading\n",
    "device: 0 # device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu\n",
    "workers: 8  # number of worker threads for data loading (per RANK if DDP)\n",
    "project: runs/custom # project name\n",
    "name: rhee # experiment name\n",
    "exist_ok: True  # whether to overwrite existing experiment\n",
    "pretrained: False  # whether to use a pretrained model\n",
    "optimizer: SGD  # optimizer to use, choices=['SGD', 'Adam', 'AdamW', 'RMSProp']\n",
    "verbose: True  # whether to print verbose output\n",
    "seed: 0  # random seed for reproducibility\n",
    "deterministic: True  # whether to enable deterministic mode\n",
    "single_cls: False  # train multi-class data as single-class\n",
    "image_weights: False  # use weighted image selection for training\n",
    "rect: False  # support rectangular training if mode='train', support rectangular evaluation if mode='val'\n",
    "cos_lr: False  # use cosine learning rate scheduler\n",
    "close_mosaic: 10  # disable mosaic augmentation for final 10 epochs\n",
    "resume: False  # resume training from last checkpoint\n",
    "min_memory: False  # minimize memory footprint loss function, choices=[False, True, <roll_out_thr>]\n",
    "# Segmentation\n",
    "overlap_mask: True  # masks should overlap during training (segment train only)\n",
    "mask_ratio: 4  # mask downsample ratio (segment train only)\n",
    "# Classification\n",
    "dropout: 0.0  # use dropout regularization (classify train only)\n",
    "\n",
    "# Val/Test settings ----------------------------------------------------------------------------------------------------\n",
    "val: True  # validate/test during training\n",
    "split: val  # dataset split to use for validation, i.e. 'val', 'test' or 'train'\n",
    "save_json: False  # save results to JSON file\n",
    "save_hybrid: False  # save hybrid version of labels (labels + additional predictions)\n",
    "conf:  # object confidence threshold for detection (default 0.25 predict, 0.001 val)\n",
    "iou: 0.7  # intersection over union (IoU) threshold for NMS\n",
    "max_det: 300  # maximum number of detections per image\n",
    "half: False  # use half precision (FP16)\n",
    "dnn: False  # use OpenCV DNN for ONNX inference\n",
    "plots: True  # save plots during train/val\n",
    "\n",
    "# Prediction settings --------------------------------------------------------------------------------------------------\n",
    "source:  # source directory for images or videos\n",
    "show: False  # show results if possible\n",
    "save_txt: False  # save results as .txt file\n",
    "save_conf: False  # save results with confidence scores\n",
    "save_crop: False  # save cropped images with results\n",
    "hide_labels: False  # hide labels\n",
    "hide_conf: False  # hide confidence scores\n",
    "vid_stride: 1  # video frame-rate stride\n",
    "line_thickness: 3  # bounding box thickness (pixels)\n",
    "visualize: False  # visualize model features\n",
    "augment: False  # apply image augmentation to prediction sources\n",
    "agnostic_nms: False  # class-agnostic NMS\n",
    "classes:  # filter results by class, i.e. class=0, or class=[0,2,3]\n",
    "retina_masks: False  # use high-resolution segmentation masks\n",
    "boxes: True  # Show boxes in segmentation predictions\n",
    "\n",
    "# Export settings ------------------------------------------------------------------------------------------------------\n",
    "format: torchscript  # format to export to\n",
    "keras: False  # use Keras\n",
    "optimize: False  # TorchScript: optimize for mobile\n",
    "int8: False  # CoreML/TF INT8 quantization\n",
    "dynamic: False  # ONNX/TF/TensorRT: dynamic axes\n",
    "simplify: False  # ONNX: simplify model\n",
    "opset:  # ONNX: opset version (optional)\n",
    "workspace: 4  # TensorRT: workspace size (GB)\n",
    "nms: False  # CoreML: add NMS\n",
    "\n",
    "# Hyperparameters ------------------------------------------------------------------------------------------------------\n",
    "lr0: 0.01  # initial learning rate (i.e. SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.01  # final learning rate (lr0 * lrf)\n",
    "momentum: 0.937  # SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8  # warmup initial momentum\n",
    "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
    "box: 7.5  # box loss gain\n",
    "cls: 0.5  # cls loss gain (scale with pixels)\n",
    "dfl: 1.5  # dfl loss gain\n",
    "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "label_smoothing: 0.0  # label smoothing (fraction)\n",
    "nbs: 64  # nominal batch size\n",
    "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
    "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
    "degrees: 0.0  # image rotation (+/- deg)\n",
    "translate: 0.1  # image translation (+/- fraction)\n",
    "scale: 0.5  # image scale (+/- gain)\n",
    "shear: 0.0  # image shear (+/- deg)\n",
    "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.0  # image flip up-down (probability)\n",
    "fliplr: 0.5  # image flip left-right (probability)\n",
    "mosaic: 1.0  # image mosaic (probability)\n",
    "mixup: 0.0  # image mixup (probability)\n",
    "copy_paste: 0.0  # segment copy-paste (probability)\n",
    "\n",
    "# Custom config.yaml ---------------------------------------------------------------------------------------------------\n",
    "cfg:  # for overriding defaults.yaml\n",
    "\n",
    "# Debug, do not modify -------------------------------------------------------------------------------------------------\n",
    "v5loader: False  # use legacy YOLOv5 dataloader\n",
    "\n",
    "# Tracker settings ------------------------------------------------------------------------------------------------------\n",
    "tracker: botsort.yaml  # tracker type, ['botsort.yaml', 'bytetrack.yaml']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5829956-19b7-47e7-976e-b012f8246646",
   "metadata": {},
   "source": [
    "# ëª¨ë¸í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2c1483-a5e4-4ad4-b0c7-0246450cba85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cfg file passed. Overriding default params with cfg/custom.yaml.\n",
      "WARNING âš ï¸ 'hide_labels' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'show_labels' instead.\n",
      "WARNING âš ï¸ 'hide_conf' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'show_conf' instead.\n",
      "WARNING âš ï¸ 'line_thickness' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'line_width' instead.\n",
      "Ultralytics YOLOv8.0.103 ğŸš€ Python-3.8.10 torch-1.13.1+cu117 CUDA:0 (Tesla V100-PCIE-32GB, 32511MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=pretrained/yolov8s.pt, data=dataset/coco128.yaml, epochs=1, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=runs/custom, name=rhee, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=False, show_conf=False, vid_stride=1, line_width=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/custom/rhee\n",
      "\n",
      "Dataset 'dataset/coco128.yaml' images not found âš ï¸, missing paths ['/home/work/workspace/experiment/yolov8/datasets/coco128/images/train2017']\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to /home/work/workspace/experiment/yolov8/datasets/coco128.zip...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d15ad9a3b849909c43b03f66fb9b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping /home/work/workspace/experiment/yolov8/datasets/coco128.zip to /home/work/workspace/experiment/yolov8/datasets...\n",
      "Dataset download success âœ… (2.2s), saved to \u001b[1m/home/work/workspace/experiment/yolov8/datasets\u001b[0m\n",
      "\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /home/work/.config/Ultralytics/Arial.ttf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce914d80fcc246b296135fa572d067b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/755k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (8)\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11166560 parameters, 11166544 gradients, 28.8 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/custom/rhee', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9435d46235144e05bb5599a6e70b7ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/work/workspace/experiment/yolov8/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<00:00, 1088.78it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/work/workspace/experiment/yolov8/datasets/coco128/labels/train2017.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/work/workspace/experiment/yolov8/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/custom/rhee/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/custom/rhee\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1      4.03G      1.039      1.035      1.197        199        640: 100% 8/8 [00:05<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:08<00:00,  2.12s/it]\n",
      "                   all        128        929      0.815      0.665      0.761      0.587\n",
      "\n",
      "1 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/custom/rhee/weights/last.pt, 22.6MB\n",
      "Optimizer stripped from runs/custom/rhee/weights/best.pt, 22.6MB\n",
      "\n",
      "Validating runs/custom/rhee/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.103 ğŸš€ Python-3.8.10 torch-1.13.1+cu117 CUDA:0 (Tesla V100-PCIE-32GB, 32511MiB)\n",
      "Model summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:06<00:00,  1.68s/it]\n",
      "                   all        128        929      0.818      0.665      0.761      0.588\n",
      "                person        128        254      0.929      0.673      0.836      0.627\n",
      "               bicycle        128          6          1      0.323      0.438      0.267\n",
      "                   car        128         46      0.794      0.217      0.398      0.226\n",
      "            motorcycle        128          5      0.813      0.878      0.928      0.763\n",
      "              airplane        128          6      0.862          1      0.995      0.791\n",
      "                   bus        128          7      0.748      0.714      0.794      0.717\n",
      "                 train        128          3          1      0.992      0.995      0.852\n",
      "                 truck        128         12      0.714      0.417      0.523      0.318\n",
      "                  boat        128          6       0.77        0.5      0.727       0.48\n",
      "         traffic light        128         14          1      0.212      0.391      0.224\n",
      "             stop sign        128          2       0.95          1      0.995      0.822\n",
      "                 bench        128          9       0.74      0.444      0.644      0.328\n",
      "                  bird        128         16      0.923          1      0.988      0.691\n",
      "                   cat        128          4      0.906          1      0.995       0.93\n",
      "                   dog        128          9      0.852      0.778      0.912      0.742\n",
      "                 horse        128          2      0.803          1      0.995      0.797\n",
      "              elephant        128         17      0.932      0.941      0.952      0.777\n",
      "                  bear        128          1      0.622          1      0.995      0.895\n",
      "                 zebra        128          4      0.883          1      0.995      0.971\n",
      "               giraffe        128          9      0.813       0.97      0.963      0.763\n",
      "              backpack        128          6      0.908        0.5      0.689      0.457\n",
      "              umbrella        128         18      0.888      0.667      0.856      0.627\n",
      "               handbag        128         19          1      0.174       0.46      0.286\n",
      "                   tie        128          7          1      0.775      0.859      0.639\n",
      "              suitcase        128          4          1      0.949      0.995      0.697\n",
      "               frisbee        128          5      0.729        0.8      0.803      0.696\n",
      "                  skis        128          1      0.811          1      0.995      0.697\n",
      "             snowboard        128          7      0.851      0.822      0.818      0.637\n",
      "           sports ball        128          6      0.697      0.667      0.637      0.421\n",
      "                  kite        128         10      0.762        0.4      0.565      0.254\n",
      "          baseball bat        128          4          1      0.411      0.722      0.277\n",
      "        baseball glove        128          7      0.956      0.429      0.431      0.255\n",
      "            skateboard        128          5      0.802        0.4      0.687      0.505\n",
      "         tennis racket        128          7      0.706      0.714       0.67      0.341\n",
      "                bottle        128         18      0.507      0.286      0.546      0.356\n",
      "            wine glass        128         16          1      0.496       0.71      0.523\n",
      "                   cup        128         36      0.931      0.378      0.776      0.503\n",
      "                  fork        128          6      0.631      0.167      0.382      0.252\n",
      "                 knife        128         16      0.898      0.553      0.813      0.564\n",
      "                 spoon        128         22      0.935      0.545      0.684      0.496\n",
      "                  bowl        128         28      0.841      0.758      0.801      0.691\n",
      "                banana        128          1      0.698          1      0.995      0.995\n",
      "              sandwich        128          2      0.577        0.5      0.828      0.737\n",
      "                orange        128          4       0.76          1      0.995      0.657\n",
      "              broccoli        128         11      0.696      0.182      0.329      0.272\n",
      "                carrot        128         24      0.773      0.542      0.732       0.54\n",
      "               hot dog        128          2      0.835          1      0.995      0.995\n",
      "                 pizza        128          5       0.83          1      0.995      0.843\n",
      "                 donut        128         14      0.783          1      0.966      0.876\n",
      "                  cake        128          4      0.863          1      0.995       0.88\n",
      "                 chair        128         35      0.516        0.4      0.536      0.319\n",
      "                 couch        128          6          1      0.745      0.955      0.776\n",
      "          potted plant        128         14      0.966      0.786      0.887      0.623\n",
      "                   bed        128          3      0.995          1      0.995      0.586\n",
      "          dining table        128         13      0.734      0.615      0.718      0.594\n",
      "                toilet        128          2      0.946          1      0.995      0.895\n",
      "                    tv        128          2      0.662          1      0.995      0.846\n",
      "                laptop        128          3      0.795      0.667      0.806      0.769\n",
      "                 mouse        128          2          1          0      0.166      0.058\n",
      "                remote        128          8          1      0.571      0.673      0.601\n",
      "            cell phone        128          8      0.796        0.5      0.513      0.313\n",
      "             microwave        128          3      0.552      0.839      0.863      0.773\n",
      "                  oven        128          5      0.429        0.4      0.365      0.302\n",
      "                  sink        128          6      0.441      0.333      0.432      0.319\n",
      "          refrigerator        128          5      0.707        0.8      0.906      0.733\n",
      "                  book        128         29      0.739      0.196      0.546      0.288\n",
      "                 clock        128          9      0.915      0.889      0.984      0.824\n",
      "                  vase        128          2       0.31          1      0.828      0.828\n",
      "              scissors        128          1          1          0          0          0\n",
      "            teddy bear        128         21      0.916      0.519      0.788      0.546\n",
      "            toothbrush        128          5      0.919        0.8       0.92       0.77\n",
      "Speed: 1.6ms preprocess, 1.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/custom/rhee\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model.train(cfg=\"cfg/custom.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a6311-08bf-4fb4-9bbc-c83dea139256",
   "metadata": {},
   "source": [
    "ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12894546-aeb1-4780-a751-6cf77266b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.103 ğŸš€ Python-3.8.10 torch-1.13.1+cu117 CUDA:0 (Tesla V100-PCIE-32GB, 32511MiB)\n",
      "Model summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/work/workspace/experiment/yolov8/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:06<00:00,  1.18it/s]\n",
      "                   all        128        929      0.812       0.67      0.767      0.592\n",
      "                person        128        254      0.929      0.669      0.832      0.624\n",
      "               bicycle        128          6          1      0.322      0.437      0.268\n",
      "                   car        128         46      0.801      0.217      0.401      0.227\n",
      "            motorcycle        128          5      0.812      0.873      0.928      0.753\n",
      "              airplane        128          6      0.863          1      0.995      0.791\n",
      "                   bus        128          7      0.813      0.714      0.791      0.714\n",
      "                 train        128          3          1       0.99      0.995      0.852\n",
      "                 truck        128         12      0.715      0.417      0.542      0.328\n",
      "                  boat        128          6      0.771        0.5      0.706      0.479\n",
      "         traffic light        128         14      0.799      0.214      0.364      0.228\n",
      "             stop sign        128          2      0.951          1      0.995      0.822\n",
      "                 bench        128          9      0.741      0.444      0.643       0.33\n",
      "                  bird        128         16      0.924          1      0.984      0.691\n",
      "                   cat        128          4      0.903          1      0.995       0.93\n",
      "                   dog        128          9      0.855      0.778       0.91      0.745\n",
      "                 horse        128          2      0.804          1      0.995      0.747\n",
      "              elephant        128         17      0.934      0.941      0.952      0.777\n",
      "                  bear        128          1      0.623          1      0.995      0.895\n",
      "                 zebra        128          4      0.883          1      0.995      0.971\n",
      "               giraffe        128          9      0.736      0.889      0.956      0.761\n",
      "              backpack        128          6      0.912        0.5      0.698      0.461\n",
      "              umbrella        128         18      0.888      0.667      0.856      0.623\n",
      "               handbag        128         19          1      0.172      0.453       0.28\n",
      "                   tie        128          7          1      0.772      0.859      0.639\n",
      "              suitcase        128          4          1       0.95      0.995      0.696\n",
      "               frisbee        128          5       0.73        0.8      0.803      0.696\n",
      "                  skis        128          1      0.818          1      0.995      0.697\n",
      "             snowboard        128          7      0.826      0.683        0.8      0.634\n",
      "           sports ball        128          6      0.691      0.667      0.637      0.421\n",
      "                  kite        128         10      0.762        0.4       0.57      0.257\n",
      "          baseball bat        128          4       0.55      0.325      0.711      0.282\n",
      "        baseball glove        128          7      0.854      0.429      0.431      0.256\n",
      "            skateboard        128          5      0.815        0.4      0.714       0.45\n",
      "         tennis racket        128          7      0.708      0.714       0.67      0.343\n",
      "                bottle        128         18      0.553      0.344      0.559      0.369\n",
      "            wine glass        128         16          1        0.5      0.789      0.553\n",
      "                   cup        128         36      0.878      0.402      0.792      0.506\n",
      "                  fork        128          6      0.662      0.167      0.354      0.244\n",
      "                 knife        128         16      0.896      0.538      0.829      0.585\n",
      "                 spoon        128         22      0.938      0.545      0.684      0.481\n",
      "                  bowl        128         28      0.868       0.75      0.794      0.675\n",
      "                banana        128          1      0.686          1      0.995      0.995\n",
      "              sandwich        128          2          1      0.868      0.995      0.995\n",
      "                orange        128          4      0.761          1      0.995      0.657\n",
      "              broccoli        128         11      0.646      0.182      0.352      0.288\n",
      "                carrot        128         24      0.784      0.607      0.739      0.541\n",
      "               hot dog        128          2      0.766          1      0.995      0.995\n",
      "                 pizza        128          5      0.875          1      0.995      0.843\n",
      "                 donut        128         14      0.784          1      0.966      0.878\n",
      "                  cake        128          4      0.862          1      0.995       0.88\n",
      "                 chair        128         35      0.538        0.4      0.536      0.307\n",
      "                 couch        128          6          1      0.744      0.955      0.776\n",
      "          potted plant        128         14      0.973      0.786      0.887      0.628\n",
      "                   bed        128          3      0.997          1      0.995      0.635\n",
      "          dining table        128         13      0.696      0.462      0.643      0.552\n",
      "                toilet        128          2      0.948          1      0.995      0.895\n",
      "                    tv        128          2      0.664          1      0.995      0.846\n",
      "                laptop        128          3      0.796      0.667      0.806       0.76\n",
      "                 mouse        128          2          1          0      0.181     0.0757\n",
      "                remote        128          8      0.882        0.5       0.64      0.562\n",
      "            cell phone        128          8      0.798        0.5      0.513      0.313\n",
      "             microwave        128          3      0.585          1      0.995      0.865\n",
      "                  oven        128          5      0.429        0.4      0.378      0.305\n",
      "                  sink        128          6      0.443      0.333      0.432      0.322\n",
      "          refrigerator        128          5      0.752          1      0.995      0.817\n",
      "                  book        128         29      0.717      0.207      0.521      0.276\n",
      "                 clock        128          9      0.917      0.889      0.984      0.815\n",
      "                  vase        128          2      0.311          1      0.828      0.828\n",
      "              scissors        128          1          1          0          0          0\n",
      "            teddy bear        128         21      0.916      0.518      0.783      0.543\n",
      "            toothbrush        128          5      0.936        0.8      0.962      0.756\n",
      "Speed: 1.3ms preprocess, 2.6ms inference, 0.0ms loss, 9.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/custom/rhee\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "metrics = model.val()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692f3eb-42ff-40f5-8878-a278411e3ab2",
   "metadata": {},
   "source": [
    "ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89474655-5088-4956-8a90-7cca5baafc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 1 bus, 10.4ms\n",
      "Speed: 3.7ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.yolo.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.yolo.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "orig_img: array([[[122, 148, 172],\n",
      "        [120, 146, 170],\n",
      "        [125, 153, 177],\n",
      "        ...,\n",
      "        [157, 170, 184],\n",
      "        [158, 171, 185],\n",
      "        [158, 171, 185]],\n",
      "\n",
      "       [[127, 153, 177],\n",
      "        [124, 150, 174],\n",
      "        [127, 155, 179],\n",
      "        ...,\n",
      "        [158, 171, 185],\n",
      "        [159, 172, 186],\n",
      "        [159, 172, 186]],\n",
      "\n",
      "       [[128, 154, 178],\n",
      "        [126, 152, 176],\n",
      "        [126, 154, 178],\n",
      "        ...,\n",
      "        [158, 171, 185],\n",
      "        [158, 171, 185],\n",
      "        [158, 171, 185]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[185, 185, 191],\n",
      "        [182, 182, 188],\n",
      "        [179, 179, 185],\n",
      "        ...,\n",
      "        [114, 107, 112],\n",
      "        [115, 105, 111],\n",
      "        [116, 106, 112]],\n",
      "\n",
      "       [[157, 157, 163],\n",
      "        [180, 180, 186],\n",
      "        [185, 186, 190],\n",
      "        ...,\n",
      "        [107,  97, 103],\n",
      "        [102,  92,  98],\n",
      "        [108,  98, 104]],\n",
      "\n",
      "       [[112, 112, 118],\n",
      "        [160, 160, 166],\n",
      "        [169, 170, 174],\n",
      "        ...,\n",
      "        [ 99,  89,  95],\n",
      "        [ 96,  86,  92],\n",
      "        [102,  92,  98]]], dtype=uint8)\n",
      "orig_shape: (1080, 810)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "speed: {'preprocess': 3.732919692993164, 'inference': 10.439634323120117, 'postprocess': 1.5454292297363281}]\n",
      "tensor([[ 19.8512, 229.2774, 805.5082, 748.2026]], device='cuda:0')\n",
      "tensor([0.9190], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "img = cv2.imread(\"data/bus.jpg\", cv2.IMREAD_COLOR)\n",
    "results = model(img)\n",
    "print(results)\n",
    "boxes = results[0].boxes\n",
    "box = boxes[0]  # returns one box\n",
    "print(box.xyxy)\n",
    "print(box.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8e463-dfd2-4360-a64e-7b4d84cc6b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "success = model.export(format=\"onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.12 / TensorFlow 2.10.1) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
